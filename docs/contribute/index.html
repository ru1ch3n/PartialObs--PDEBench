<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Contribute</title>
  <link rel="stylesheet" href="../assets/style.css" />
  
</head>

<body>
  <header class="hero">
    <div class="container">
      <div class="hero-top">
        <div>
          <h1>Contribute</h1>
          <p class="subtitle">How to add and curate papers (YAML-first).</p>
          
        </div>

        
      </div>

      <nav class="nav"><a href="../index.html">Home</a><a href="../research/">Research</a><a href="../pde-problems/">PDE problems</a><a href="../baselines/">Baselines</a><a href="../benchmark/">Benchmark</a><a href="../contribute/" aria-current="page">Contribute</a></nav>
    </div>
  </header>

  <main class="container">
    
<section class="section">
  <h2>Contribute</h2>
  <p>
    The site is <b>YAML-first</b>: paper metadata + summaries live in <code>data/papers/</code>,
    and the website under <code>docs/</code> is generated from those YAML files.
  </p>
  <ul>
    <li><b>Index placeholders</b> (status=<code>index</code>) are quick to add: title/authors/venue/links.</li>
    <li><b>Curated pages</b> (status=<code>curated</code>) include structured notes: contributions, baselines, results, etc.</li>
  </ul>
  <div class="note">
    Current DB: <b>300</b> papers (<b>46</b> curated).
  </div>
</section>

<section class="section">
  <h2>Add a paper (one-by-one)</h2>
  <ol>
    <li>Copy <code>data/papers/_template.yaml</code> → create <code>data/papers/&lt;slug&gt;.yaml</code>.</li>
    <li>Fill the required metadata: title, authors, year, venue, links.</li>
    <li>Start with <code>status: index</code>. Later upgrade to <code>status: curated</code> with more fields.</li>
    <li>Run validation + site generation:</li>
  </ol>
  <pre class="code"><code># Validate YAML (fast)
python scripts/validate_papers.py

# Regenerate docs/ (GitHub Pages output)
python scripts/generate_research_site.py
</code></pre>
</section>

<section class="section">
  <h2>Submit to GitHub (so the website updates)</h2>
  <p>
    GitHub Pages serves this website from the <code>docs/</code> folder.
    After you edit YAML files, make sure you regenerate the site, then commit + push.
  </p>
  <pre class="code"><code># After regenerating docs/, commit and push.

git status
git add -A
git commit -m &quot;Update papers and regenerate site&quot;
git push origin main

# If Git complains about missing user identity:
git config --global user.name &quot;Your Name&quot;
git config --global user.email &quot;you@example.com&quot;
</code></pre>
  <div class="note">
    Tip: if you are contributing via a pull request, do these steps on a feature branch and then open a PR.
  </div>
</section>

<section class="section">
  <h2>YAML format</h2>
  <p>
    Minimal fields are enough for an index entry. For curated pages, please also fill
    <code>tldr</code>, <code>problem</code>, <code>contrib</code>, <code>baselines</code>, and <code>main_results</code>.
  </p>
  <pre class="code"><code>slug: my-paper-2025
status: index   # or: curated
category: AI4PDE
method_class: NeuralOperator

full_title: Full paper title goes here
short_title: MyPaper
authors: First Author; Second Author; ...
year: 2025
venue: ICLR

links:
  paper: https://arxiv.org/abs/xxxx.xxxxx
  code: https://github.com/user/repo

tldr: &gt;-
  2–4 sentences: setting → method → key result (include dataset/metric if possible).

problem: &gt;-
  What problem does this paper solve? Be concrete (PDE, observation type, task).

contrib:
  - Main contribution #1
  - Main contribution #2

benefits:
  - What is better compared to common baselines?

baselines:
  - FNO
  - PINO

main_results:
  - metric: relative L2 error
    value: 0.012
    dataset: PDEBench Navier–Stokes
    compared_to: FNO

interesting: &gt;-
  Any notable detail (failure mode, trick, surprising ablation, limitation).

bibkey: MyPaper2025
bibtex: |
  @inproceedings{MyPaper2025,
    title={...},
    author={...},
    booktitle={ICLR},
    year={2025},
    url={https://...}
  }
</code></pre>
</section>

<section class="section">
  <h2>Bulk import from conferences (ICLR / ICML / NeurIPS)</h2>
  <p>
    If you want to include <b>many papers</b> (e.g., all accepted papers for the last 5 years),
    the recommended workflow is:
  </p>
  <ol>
    <li>Get a <b>BibTeX</b> file for the conference/year.</li>
    <li>Convert BibTeX → YAML stubs with <code>scripts/import_bibtex_to_yaml.py</code>.</li>
    <li>Curate a subset (set <code>status: curated</code> + fill the summary fields) over time.</li>
  </ol>
  <pre class="code"><code># 1) Download a conference BibTeX file (ICLR/ICML/NeurIPS).
# 2) Convert it into YAML stubs (status=index) under data/papers/import/...

python scripts/import_bibtex_to_yaml.py   --bib path/to/ICLR_2025.bib   --venue ICLR   --out data/papers/import/iclr2025   --status index

# Optional: only keep likely AI4PDE/AI4SDE papers by title keywords
python scripts/import_bibtex_to_yaml.py   --bib path/to/ICLR_2025.bib   --venue ICLR   --out data/papers/import/iclr2025   --status index   --keywords &quot;pde,operator,neural operator,physics-informed,navier,burgers,sde,diffusion&quot;
</code></pre>
  <div class="note">
    Tip: importing <i>all</i> papers from top conferences can produce a very large DB.
    For AI4PDE focus, start with keyword-filtered imports and gradually expand.
  </div>
</section>

<section class="section">
  <h2>Export BibTeX from the website</h2>
  <p>
    The Research page supports batch BibTeX export:
  </p>
  <pre class="code"><code>1) Go to the Research tab.
2) Tick the “Pick” checkbox for the papers you want.
3) Click “Download .bib” (or “Copy BibTeX”).
</code></pre>
  <p class="muted">
    If a paper YAML includes <code>bibtex:</code>, we export that. Otherwise we generate a minimal BibTeX entry from metadata.
  </p>
</section>

<section class="section">
  <h2>Quality bar for curated pages</h2>
  <ul>
    <li><b>Main contribution:</b> 2–5 bullets that are specific (not marketing language).</li>
    <li><b>Problem & setting:</b> PDE(s), observation type (masked pixels / sparse sensors / partial trajectories), task (forecasting / inverse / reconstruction).</li>
    <li><b>Baselines:</b> methods actually compared in the paper (FNO/PINO/UNet/etc.).</li>
    <li><b>Main results:</b> include metric + dataset + comparison target (even 1–2 rows are useful).</li>
  </ul>
</section>


    <footer class="footer">
      <div class="muted">Last generated: 2026-01-20</div>
    </footer>
  </main>
</body>
</html>
