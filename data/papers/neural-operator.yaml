# This file is the source-of-truth for the paper page on the website.
# Edit fields to curate experiments/baselines/results.
slug: neural-operator
short_title: Neural Operator
full_title: 'Neural Operators: Learning Maps Between Function Spaces'
authors: Nikolaos Kovachki et al.
year: 2021
category: Neural operators
badges:
- Operator learning
- Survey/Foundations
tagline: Unifies operator-learning views (integral, Fourier, graph) for PDEs.
quick_facts:
- 'Type: operator learning'
- 'View: maps between function spaces'
- Covers many neural operator families
links:
  paper: https://arxiv.org/abs/2108.08481
  paper_label: arXiv:2108.08481
tldr: Neural operator work formalizes learning solution operators (function-to-function maps) and connects integral, Fourier, and graph-based variants.
contrib:
- Frames PDE surrogate learning as operator learning between function spaces.
- Connects several architectures (kernel/integral, Fourier, graph) under a common viewpoint.
- Provides theoretical and empirical grounding for resolution-invariant surrogate solvers.
pdes:
- Burgers
- Darcy flow
- Navierâ€“Stokes
tasks:
- Operator learning (resolution generalization)
- Fast surrogate simulation
baselines:
- DeepONet
- FNO
setting:
- Highlights training on low-res and testing on higher-res (discretization-invariant).
- Emphasizes parametric PDE families and solution operators.
results_tables:
- title: Representative results (high level)
  header:
  - Benchmark
  - Metric
  - Reported takeaway
  rows:
  - - Darcy / NS / Burgers
    - L2 / rollout error
    - Neural operators achieve strong accuracy and generalize across resolutions compared to classical CNN baselines.
status: curated
method_class: Operator learning
auto:
  pdes: []
  tasks: []
