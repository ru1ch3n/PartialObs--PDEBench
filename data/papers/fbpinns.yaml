# This file is the source-of-truth for the paper page on the website.
# Edit fields to curate experiments/baselines/results.
slug: fbpinns
short_title: FBPINNs
full_title: 'FBPINNs: Finite Basis Physics-Informed Neural Networks'
authors: Benjamin Moseley et al.
year: 2021
category: Physics-informed optimization
badges:
- PINN
- Domain decomposition
tagline: Domain decomposition for PINNs using finite bases.
quick_facts:
- 'Type: PINN variant'
- 'Strategy: finite basis / decomposition'
- 'Targets: harder PDEs'
links:
  paper: https://arxiv.org/abs/2107.07871
  paper_label: arXiv:2107.07871
tldr: FBPINNs use a finite-basis/domain-decomposition style formulation to improve PINN training and scalability on harder PDEs.
contrib:
- Decomposes the domain and combines local PINN components.
- Improves training stability/scalability vs monolithic PINNs.
- Enables solving more challenging PDE problems with PINN-like constraints.
pdes:
- Poisson
- Burgers
- Wave equation
tasks:
- Forward PDE solve
- Inverse/parameter inference (in some settings)
baselines:
- PINN
- XPINN
setting:
- Splits the domain and optimizes multiple local networks.
- Uses physics residuals and continuity constraints between subdomains.
results_tables:
- title: Key results
  header:
  - Aspect
  - Metric
  - Reported takeaway
  rows:
  - - Training stability
    - Loss convergence
    - More stable optimization than single-network PINNs on challenging PDEs.
  - - Scalability
    - Runtime vs accuracy
    - Domain decomposition helps scale PINN-style training.
status: curated
method_class: PINN / physics-constrained
auto:
  pdes: []
  tasks: []
