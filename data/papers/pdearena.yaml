# This file is the source-of-truth for the paper page on the website.
# Edit fields to curate experiments/baselines/results.
slug: pdearena
short_title: PDEArena
full_title: 'PDEArena: A Benchmark for Learning PDEs'
authors: Tariq et al. (see paper)
year: 2022
category: Benchmarks & datasets
badges:
- Benchmark
- Operator learning
tagline: Benchmarking neural PDE models on fluid mechanics tasks.
quick_facts:
- 'Type: benchmark dataset'
- 'Focus: spatiotemporal PDE modeling'
- Includes standardized training/eval
links:
  paper: https://arxiv.org/abs/2209.15616
  paper_label: arXiv:2209.15616
tldr: PDEArena proposes a benchmark for spatiotemporal PDE modeling, enabling consistent comparison between neural PDE solvers and operators.
contrib:
- Provides datasets + protocols for training/evaluating neural PDE models.
- Focus on fluid-mechanics style PDE trajectories and generalization.
- Encourages standardized reporting and baselines.
pdes:
- Navierâ€“Stokes
- Shallow water
- Maxwell
tasks:
- Sequence prediction
- Generalization across regimes
baselines:
- FNO
- ResNet
- U-Net
- Transformer
setting:
- Standardized training/eval splits; rollout prediction; multiple variables.
results_tables:
- title: What to look at
  header:
  - Item
  - Metric
  - Why it matters
  rows:
  - - Rollout error
    - MSE / L2
    - Captures stability and long-horizon drift.
  - - Generalization
    - Error under shift
    - Measures robustness across parameter regimes.
status: curated
method_class: Benchmark
auto:
  pdes: []
  tasks: []
